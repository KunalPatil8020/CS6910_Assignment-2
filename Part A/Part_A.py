# -*- coding: utf-8 -*-
"""Part_A.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HPYEvT9YdPGBL5ipU6eWoxRNa43c4ycs
"""

#Import libraries
import os
import random
import shutil
import tensorflow as tf
import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator

!gdown https://storage.googleapis.com/wandb_datasets/nature_12K.zip

!unzip "/content/nature_12K.zip"

! pip install wandb

!wandb login

!find . -name "*.DS_Store" -type f -delete

"""# Importing libraries"""

import numpy as np
import os
import matplotlib.pyplot as plt
import keras
from keras.layers import Conv2D , MaxPool2D , Flatten , Dropout, Dense, Activation, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report,confusion_matrix
import seaborn as sns
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from keras.models import Sequential, load_model
import random
import wandb
import shutil
from tqdm import tqdm
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ModelCheckpoint
from wandb.keras import WandbCallback
from keras.utils.vis_utils import plot_model

"""# Exploring the data"""

# list of class names
temp = os.listdir("inaturalist_12K/train")
class_names = [name for name in temp if name != ".DS_Store"]
print("The names of the classes are:")
print(class_names)

num_classes = len(class_names)
print(f"Number of classes = {num_classes}\n")

M = 0
M_test = 0

for each_class in class_names:
    train_images = os.listdir("inaturalist_12K/train/"+each_class)
    test_images = os.listdir("inaturalist_12K/val/"+each_class)
    filtered_images = list(filter(lambda x: x!=".DS_Store", train_images))
    filtered_test_images = list(filter(lambda x: x!=".DS_Store", test_images))
    M = M + len(filtered_images)
    M_test = M_test + len(filtered_test_images)

print(f"Total number of training images = {M}")
print(f"Total number of test images = {M_test}\n")

input_image_shape = (224, 224, 3)

"""# Creating validation set"""

# Fraction of images to use in the validationset
validation_split_fraction = 0.1

try:
    shutil.rmtree("inaturalist_12K/validation/")
except:
    pass
    
# Create a new directory for the validation set
os.mkdir("inaturalist_12K/validation/")

for each_class in class_names:
    os.mkdir("inaturalist_12K/validation/"+each_class)
    train_images = os.listdir("inaturalist_12K/train/"+each_class)
    filtered_images = list(filter(lambda x: x!=".DS_Store", train_images))
    count = len(filtered_images)
    random.shuffle(filtered_images) # Shuffle the training images

    validation_images = filtered_images[:round(validation_split_fraction*count)]

    for im in validation_images:
        shutil.move("inaturalist_12K/train/"+each_class+"/"+im, "inaturalist_12K/validation/"+each_class+"/"+im)

"""# Set up the training, validation and test generators"""

def generators(train_batch_size, data_aug):
    if data_aug:
        train_datagen = ImageDataGenerator(rescale=1./255,
                                        height_shift_range=0.2,
                                        width_shift_range=0.2,
                                        horizontal_flip=True,
                                        zoom_range=0.2,
                                        fill_mode="nearest")
    else:
        train_datagen = ImageDataGenerator(rescale=1./255)

    val_datagen = ImageDataGenerator(rescale=1./255)

    test_datagen = ImageDataGenerator(rescale=1./255)

    train_generator = train_datagen.flow_from_directory(
        'inaturalist_12K/train',
        target_size=input_image_shape[:2],
        color_mode="rgb",
        batch_size=train_batch_size,
        class_mode='categorical',
        shuffle=True,
        seed=42)

    # batch_size for validation and test generator should perfectly divide the total number of examples
    validation_generator = val_datagen.flow_from_directory(
        'inaturalist_12K/validation',
        target_size=input_image_shape[:2],
        color_mode="rgb",
        batch_size=100,
        class_mode='categorical',
        shuffle=True,
        seed=42)

    test_generator = test_datagen.flow_from_directory(
        'inaturalist_12K/val',
        target_size=input_image_shape[:2],
        color_mode="rgb",
        batch_size=100,
        class_mode=None,
        shuffle=False,
        seed=42)
    
    return train_generator, validation_generator, test_generator

"""# Building the model"""

def define_model(activation_function_conv, activation_function_dense, num_filters, shape_of_filters_conv, shape_of_filters_pool, batch_norm_use, fc_layer, dropout):
    model = Sequential()
    model.add(Conv2D(num_filters[0], shape_of_filters_conv[0], input_shape=input_image_shape))
    if batch_norm_use:
        model.add(BatchNormalization())
    model.add(Activation(activation_function_conv[0]))
    model.add(MaxPool2D(pool_size=shape_of_filters_pool[0], strides = (2, 2)))

    for i in range(1, 5):
        model.add(Conv2D(num_filters[i], shape_of_filters_conv[i]))
        if batch_norm_use:
            model.add(BatchNormalization())
        model.add(Activation(activation_function_conv[i]))
        model.add(MaxPool2D(pool_size=shape_of_filters_pool[i], strides = (2, 2)))

    model.add(Flatten()) # The flatten layer is essential to convert the feature map into a column vector
    model.add(Dense(fc_layer, activation=activation_function_dense))
    model.add(Dropout(dropout)) # For regularization
    model.add(Dense(10, activation="softmax"))
    return model

def train_validate_model(train_batch_size, data_aug, activation_function_conv, activation_function_dense, num_filters, shape_of_filters_conv, shape_of_filters_pool, batch_norm_use, fc_layer, dropout):
    
    # Create the data generators
    if data_aug:
        train_datagen = ImageDataGenerator(rescale=1./255,
                                        height_shift_range=0.2,
                                        width_shift_range=0.2,
                                        horizontal_flip=True,
                                        zoom_range=0.2,
                                        fill_mode="nearest")
    else:
        train_datagen = ImageDataGenerator(rescale=1./255)

    test_datagen = ImageDataGenerator(rescale=1./255)

    train_generator = train_datagen.flow_from_directory(
        'inaturalist_12K/train',
        target_size=input_image_shape[:2],
        color_mode="rgb",
        batch_size=train_batch_size,
        class_mode='categorical',
        shuffle=True,
        seed=42)

    test_generator = test_datagen.flow_from_directory(
        'inaturalist_12K/val',
        target_size=input_image_shape[:2],
        color_mode="rgb",
        batch_size=train_batch_size,
        class_mode=None,
        shuffle=False,
        seed=42)
    
    # Define the model
    model = define_model(activation_function_conv, activation_function_dense, num_filters, shape_of_filters_conv, shape_of_filters_pool, batch_norm_use, fc_layer, dropout)

    # Compute the validation step size
    TRAIN_STEP_SIZE = train_generator.n//train_generator.batch_size

    model.compile(optimizer=Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])

    history = model.fit(train_generator,
                        steps_per_epoch = TRAIN_STEP_SIZE,
                        epochs=10,
                        verbose=2)
    
    plt.plot(history.history['accuracy'])
    plt.title('Model accuracy')
    plt.ylabel('Training accuracy')
    plt.xlabel('Epoch')
    plt.show()
    
    plt.plot(history.history['loss'])
    plt.title('Model loss')
    plt.ylabel('Training loss')
    plt.xlabel('Epoch')
    plt.show()
    
    return history, model



def train_validate_model_wandb():
    # Default values for hyper-parameters
    config_defaults = {
        "data_aug": True,
        "train_batch_size": 128,
        "batch_norm_use": True,
        "dropout": 0,
        "num_filters": [16, 32, 64, 128, 256],
        "fc_layer": 256,
        "shape_of_filters_conv": [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3)]
    }

    # Initialize a new wandb run
    wandb.init(config=config_defaults)
    
    # Config is a variable that holds and saves hyperparameters and inputs
    config = wandb.config

    # Local variables, values obtained from wandb config
    num_filters = config.num_filters
    data_aug = config.data_aug
    train_batch_size = config.train_batch_size
    batch_norm_use = config.batch_norm_use
    dropout = config.dropout
    fc_layer = config.fc_layer
    shape_of_filters_conv = config.shape_of_filters_conv
    
    # Display the hyperparameters
    run_name = "aug_{}_bs_{}_bn_{}_drop_{}_fc_{}_fil_{}_shape_{}".format(data_aug, train_batch_size, batch_norm_use, dropout, fc_layer, num_filters, shape_of_filters_conv)
    print(run_name)

    # Create the data generators
    train_generator, validation_generator, test_generator = generators(train_batch_size, data_aug)
    
    # Define the model
    model = define_model(activation_function_conv, activation_function_dense, num_filters, shape_of_filters_conv, shape_of_filters_pool, batch_norm_use, fc_layer, dropout)
    print(model.count_params())

    TRAIN_STEP_SIZE = train_generator.n//train_generator.batch_size
    VALIDATION_STEP_SIZE = validation_generator.n//validation_generator.batch_size

    model.compile(optimizer=Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])

    # Early Stopping callback
    earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')

    # To save the model with best validation accuracy
    mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)

    history = model.fit(train_generator,
                        steps_per_epoch = TRAIN_STEP_SIZE,
                        validation_data = validation_generator,
                        validation_steps = VALIDATION_STEP_SIZE,
                        epochs=10, 
                        callbacks=[WandbCallback(data_type="image", generator=validation_generator), earlyStopping, mc],
                        verbose=2)
    
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Validation'], loc='upper left')
    plt.show()
    
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Validation'], loc='upper left')
    plt.show()
    
    # Meaningful name for the run
    wandb.run.name = run_name
    wandb.run.save()
    wandb.run.finish()
    return history

"""# Hyperparameter Search using WandB"""

# These are the hyperparameters that we do not sweep over
activation_function_conv = ["relu", "relu", "relu", "relu", "relu"]
activation_function_dense = "relu"
shape_of_filters_pool = [(2, 2), (2, 2), (2, 2), (2, 2), (2, 2)]

# Sweep configuration
sweep_config = {
  "name": "Sweep 2 CS6910 Assignment 2 - Part A",
  "metric": {
      "name":"val_accuracy",
      "goal": "maximize"
  },
  "method": "bayes",
  "parameters": {
        "data_aug": {
            "values": [True, False]
        },
        "train_batch_size": {
            "values": [128, 256]
        },
        "batch_norm_use": {
            "values": [True, False]
        },
        "dropout": {
            "values": [0.1, 0, 0.2]
        },
        "num_filters": {
            "values": [[16, 32, 64, 128, 256], [32, 64, 128, 256, 512], [32, 32, 32, 32, 32],
                       [256, 128, 64, 32, 16], [64, 128, 256, 512, 1024], [128, 64, 32, 16, 8]]
        },
        "fc_layer": {
            "values": [512,256,128]
        },
        "shape_of_filters_conv": {
            "values": [[(3, 3), (3, 3), (3, 3), (5, 5), (7, 7)],
                       [(3, 3), (3, 3), (3, 3), (3, 3), (3, 3)],
                       [(7, 7), (5, 5), (3, 3), (3, 3), (3, 3)]]
        }
    }
}

# Generates a sweep id
sweep_id = wandb.sweep(sweep_config, project="Assg-2", entity="kunal_patil")
wandb.agent(sweep_id, train_validate_model_wandb, count=100)

"""# Training a model with the best set of hyperparameters"""

# Transferring the validation images back into the training set
for each_class in class_names:
    # Get the validation images of each class
    validation_images = os.listdir("inaturalist_12K/validation/"+each_class)
    filtered_vaidation_images = list(filter(lambda x: x!=".DS_Store", validation_images))

    for im in filtered_vaidation_images:
        # Transfer images from the validation to training folders
        shutil.move("inaturalist_12K/validation/"+each_class+"/"+im, "inaturalist_12K/train/"+each_class+"/"+im)

# These are the hyperparameters that we do not sweep over
activation_function_conv = ["relu", "relu", "relu", "relu", "relu"]
activation_function_dense = "relu"
shape_of_filters_pool = [(2, 2), (2, 2), (2, 2), (2, 2), (2, 2)]

# Best values of hyperparameters chosen using wandb sweeps
data_aug = True
train_batch_size = 128
batch_norm_use = True
dropout = 0.1

# Number of filters in each layer
num_filters = [32, 64, 128, 256, 512]
# Number of neurons in the dense/fully connected layer
fc_layer = 512
# Shape of the filters used in each of the five layers
shape_of_filters_conv = [(3, 3), (3, 3), (3, 3), (5, 5), (7, 7)]

# Training the model
history, model = train_validate_model(train_batch_size,
                               data_aug,
                               activation_function_conv,
                               activation_function_dense,
                               num_filters,
                               shape_of_filters_conv, 
                               shape_of_filters_pool,
                               batch_norm_use,
                               fc_layer,
                               dropout)

# Saving the model in H5 format
model.save("best_cnn_model.h5")
from google.colab import drive
drive.mount('/content/drive')
model.save("/content/drive/My Drive/CS6910_DL/Assignment_2/model-best.h5")

os.chdir('drive/My Drive/CS6910_DL/Assignment_2')

# Load the saved model
from keras.models import load_model
model = load_model("model-best.h5")

print(model.summary())

plot_model(model)

"""# Testing and Prediction Section"""

# Import libraries
import numpy as np
import os
import matplotlib.pyplot as plt
import keras
from keras.layers import Conv2D , MaxPool2D , Flatten , Dropout, Dense, Activation, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report,confusion_matrix
import seaborn as sns
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from keras.models import Sequential, load_model
import random
import wandb
import shutil
from tqdm import tqdm
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ModelCheckpoint
#from wandb.keras import WandbCallback
from keras.utils.vis_utils import plot_model

!gdown https://drive.google.com/file/d/1EM0J0rU1le3oV1GPUfMO-LcMu1JiG4yx/view?usp=sharing

# Load the saved model
from keras.models import load_model
model = load_model("model-best.h5")
# Input image shape
input_image_shape = (224, 224, 3)

# Predictions on the training set

# Create a train data generator
train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
        'inaturalist_12K/train',
        target_size=input_image_shape[:2],
        color_mode="rgb",
        batch_size=128,
        class_mode='categorical',
        shuffle=True,
        seed=42)

# Evaluation on the training set
loss, accuracy = model.evaluate(train_generator) 
print(f"Training accuracy = {accuracy*100} %")

test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
        'inaturalist_12K/val',
        target_size=input_image_shape[:2],
        color_mode="rgb",
        batch_size=100,
        class_mode='categorical',
        shuffle=False,
        seed=42)

test_predictions = np.argmax(model.predict(test_generator), axis=-1)
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test accuracy = {test_accuracy*100} %")

wandb.init(project="Assg-2", entity="kunal_patil", name="Q.4")

# sample image and prediction from the test dataset
class_names = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']
plt.figure(figsize=(20, 60))
wandb_img = []
wandb_title = []
for i in range(10*3):
    ax = plt.subplot(10, 3, i + 1)
    image, label = test_generator.next()
    predicted_label = model.predict(image)
    title_ = str("Actual Label : ") + class_names[np.where(label[0,:] == 1)[0][0]] + "\n" + str("Predicted Label : ") + class_names[np.where(predicted_label == np.amax(predicted_label))[1][0]]
    wandb_img.append(image[0])
    wandb_title.append(title_)
    plt.imshow(image[0])
    plt.title(title_)
for j in range(len(wandb_img)):
  wandb.log({"sample image and prediction from the test dataset": [wandb.Image(wandb_img[j], caption=wandb_title[j])]})

"""# Filters"""

layer = model.layers[0]
filters, biases = layer.get_weights()

# normalize filter values to 0-1 so we can visualize them
f_min, f_max = filters.min(), filters.max()
filters = (filters - f_min) / (f_max - f_min)

num_filters = filters.shape[-1]

print(f"Shape of each filter = {filters.shape[:-1]}")
print(f"Number of filters = {num_filters}")

wandb.init(project="Assg-2", entity="kunal_patil", name="Filters")
k = 1
plt.figure(figsize=(6, 48))
wandb_img = []
for i in range(num_filters):
    for j in range(3):
        f = filters[:, :, j, i]
        plt.subplot(num_filters, 3, k)
        k = k + 1
        plt.imshow(f, cmap="gray")
        plt.axis("off")
        wandb_img.append(f)
#plt.show()
for j in range(len(wandb_img)):
  wandb.log({"Filters": [wandb.Image(wandb_img[j])]})

"""# Guided Backpropagation"""

import os
os.environ['DISABLE_COLAB_TF_IMPORT_HOOK'] = '1'

# Import the required libraries
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
tf.compat.v1.enable_eager_execution()
import numpy as np
import matplotlib.pyplot as plt
from keras.models import load_model
import shutil
import os

from google.colab import drive
drive.mount('/content/drive')
os.chdir('drive/My Drive/CS6910_DL/Assignment_2')
model=tf.keras.models.load_model('model-best.h5')

# Choose a random image from the dataset
random_class = os.listdir("inaturalist_12K/train/")[np.random.randint(0, 10)]
random_class_images = os.listdir("inaturalist_12K/train/"+random_class)
random_image = random_class_images[np.random.randint(0, len(random_class_images))]

# Load the random image that we will use for guided backpropagation
img = tf.keras.preprocessing.image.load_img("inaturalist_12K/train/"+random_class+"/"+random_image,
                                            target_size=(227, 227))

# Display the random image
plt.imshow(img)
plt.axis("off")
plt.title("Random Image from the dataset")
plt.show()

wandb.init(project="Assg-2", entity="kunal_patil", name="Guided Backpropagation")
# This custom model has the 5th convolutional layer as its final layer
guided_backprop_model = tf.keras.models.Model(inputs = [model.inputs], outputs = [model.get_layer(index=-8).output])
# Here we choose only those layers that have an activation attribute
layer_dictionary = [layer for layer in guided_backprop_model.layers[1:] if hasattr(layer,'activation')]

# Define a custom gradient for the version of ReLU needed for guided backpropagation
@tf.custom_gradient
def guidedbackpropRelu(x):
    def grad(dy):
        return tf.cast(dy>0,"float32") * tf.cast(x>0, "float32") * dy
    return tf.nn.relu(x), grad

for l in layer_dictionary:
    # Change the ReLU activation to supress the negative gradients
    if l.activation == tf.keras.activations.relu:
        l.activation = guidedbackpropRelu

# The shape of the layer that we are interested in
conv_output_shape = model.layers[-8].output.shape[1:]

plt.figure(figsize=(30, 60))
for i in range(10):
    # Index of a random pixel
    neuron_index_x = np.random.randint(0, conv_output_shape[0])
    neuron_index_y = np.random.randint(0, conv_output_shape[1])
    neuron_index_z = np.random.randint(0, conv_output_shape[2])

    # Mask to focus on the outputs of only one neuron in the last convolution layer
    masking_matrix = np.zeros((1, *conv_output_shape), dtype="float")
    masking_matrix[0, neuron_index_x, neuron_index_y, neuron_index_z] = None

    # Calculate the gradients
    with tf.GradientTape() as tape:
        inputs = tf.cast(np.array([np.array(img)]), tf.float32)
        tape.watch(inputs)
        outputs = guided_backprop_model(inputs) * masking_matrix

    grads_visualize = tape.gradient(outputs, inputs)[0]

    # Visualize the output of guided backpropagation
    img_guided_bp = np.dstack((grads_visualize[:, :, 0], grads_visualize[:, :, 1], grads_visualize[:, :, 2],)) 

    # Scaling to 0-1      
    img_guided_bp = img_guided_bp - np.min(img_guided_bp)
    img_guided_bp /= img_guided_bp.max()
    plt.subplot(10, 1, i+1)
    plt.imshow(img_guided_bp)
    wandb_img.append(img_guided_bp)
    plt.axis("off")
plt.show()